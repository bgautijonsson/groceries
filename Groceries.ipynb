{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import h5py\n",
    "import datetime\n",
    "from tensorflow.python.framework import ops\n",
    "import scipy.io\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Breyta flokkabreytu í 1 vs 0 dummy breytu\n",
    "def make_dummy_variable(dataframe, column_name):\n",
    "    for elem in dataframe[column_name].unique():\n",
    "        dataframe[str(column_name) + \"_\" + str(elem)] = (dataframe[column_name] == elem)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def days_before_holiday(dataframe, number):\n",
    "    for i in xrange(len(national_holidays['days'].unique())):\n",
    "        dataframe[str(number)+'_days_before_festival_' + str(i)] = dataframe['days'] == (national_holidays['days'].unique()[i] - number)\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gögnin lesin\n",
    "Byrjum á því að lesa gögnin með Pandas. Lesum bara hluta af training safninu eins og er. Svo joinum við töflurnar saman í eina stóra töflu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"./data/items.csv\")\n",
    "stores = pd.read_csv(\"./data/stores.csv\")\n",
    "transactions = pd.read_csv(\"./data/transactions.csv\")\n",
    "oil = pd.read_csv(\"./data/oil.csv\")\n",
    "holidays = pd.read_csv(\"./data/holidays_events.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nrows\n",
    "\n",
    "Ef þú tekur út \"nrows = ....\" fyrir neðan lestu inn allt gagnasafnið. Getur líka prófað að auka lesturshlutfallið hægt og rólega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 100000\n",
    "train = pd.read_csv(\"./data/train.csv\", nrows=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pd.merge(train, items, how=\"inner\")\n",
    "combined = pd.merge(combined, oil, how = \"inner\")\n",
    "combined = pd.merge(combined, stores, how = \"inner\")\n",
    "combined = pd.merge(combined, transactions, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined['date'] = pd.to_datetime(combined['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mjög mikið NA í \"onpromotion\" gætum kannski gert eitthvað við þessa breytu samt\n",
    "combined = combined.loc[:,combined.columns != 'onpromotion']\n",
    "combined = combined.loc[:, combined.columns != 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays['date'] = pd.to_datetime(holidays['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays['days'] = (holidays['date'] - pd.datetime(2013, 1, 1)).dt.days\n",
    "combined['days'] = (combined['date'] - pd.datetime(2013, 1, 1)).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays = holidays.loc[holidays['days'] >= 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "national_holidays = holidays.loc[holidays['locale'] == 'National',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    4,   11,   41,   42,  118,  120,  130,  131,  143,  221,\n",
       "        281,  283,  305,  306,  354,  355,  356,  357,  358,  359,  364,\n",
       "        365,  426,  427,  472,  485,  494,  495,  508,  527,  530,  535,\n",
       "        540,  543,  544,  545,  546,  549,  550,  553,  554,  557,  558,\n",
       "        586,  646,  647,  670,  671,  696,  699,  718,  719,  720,  721,\n",
       "        722,  723,  724,  729,  730,  731,  739,  776,  777,  822,  850,\n",
       "        858,  859,  873,  951, 1011, 1035, 1036, 1060, 1063, 1084, 1085,\n",
       "       1086, 1087, 1088, 1089, 1094, 1095, 1133, 1134, 1179, 1201, 1202,\n",
       "       1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213,\n",
       "       1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224,\n",
       "       1225, 1226, 1227, 1228, 1229, 1230, 1231, 1239, 1242, 1317, 1319,\n",
       "       1377, 1401, 1402, 1403, 1411, 1424, 1427, 1450, 1451, 1452, 1453,\n",
       "       1454, 1455, 1460, 1461, 1462, 1518, 1519, 1564, 1581, 1593, 1594,\n",
       "       1604, 1606, 1682, 1683, 1742, 1766, 1767, 1815, 1816, 1817, 1818,\n",
       "       1819, 1820])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_holidays['days'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    combined = days_before_holiday(combined, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X/y split\n",
    "Skiptum upp í X og y flokka. Viljum spá fyrir um unit sales. Svo gerum við smá preprocessing á X. Búum til dummy variables út frá flokkabreytum o.s.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = combined['unit_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'date', u'store_nbr', u'item_nbr', u'family', u'class', u'perishable',\n",
       "       u'dcoilwtico', u'city', u'state', u'type',\n",
       "       ...\n",
       "       u'9_days_before_festival_146', u'9_days_before_festival_147',\n",
       "       u'9_days_before_festival_148', u'9_days_before_festival_149',\n",
       "       u'9_days_before_festival_150', u'9_days_before_festival_151',\n",
       "       u'9_days_before_festival_152', u'9_days_before_festival_153',\n",
       "       u'9_days_before_festival_154', u'9_days_before_festival_155'],\n",
       "      dtype='object', length=1573)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = combined.loc[:,combined.columns != 'unit_sales']\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/notandi/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Breyta dagsetningu í int sem stendur fyrir fjölda daga frá fyrstu mælingu\n",
    "X['date'] = (X['date'] - pd.datetime(2013, 1, 1)).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Þessar breytur leyfa networkinu að læra sjálfkrafa seasonality út frá mánuðum og vikum\n",
    "X['month_sin'] = np.sin(2*math.pi*X['date'].values/12)\n",
    "X['month_cos'] = np.cos(2*math.pi*X['date'].values/12)\n",
    "X['week_sin'] = np.sin(2*math.pi*X['date'].values/52)\n",
    "X['week_cos'] = np.cos(2*math.pi*X['date'].values/52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = ['store_nbr', 'item_nbr', 'family', 'class', 'perishable', 'city', 'state', 'type', 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished dummying variable: store_nbr\n",
      "Finished dummying variable: item_nbr\n",
      "Finished dummying variable: family\n",
      "Finished dummying variable: class\n",
      "Finished dummying variable: perishable\n",
      "Finished dummying variable: city\n",
      "Finished dummying variable: state\n",
      "Finished dummying variable: type\n",
      "Finished dummying variable: cluster\n"
     ]
    }
   ],
   "source": [
    "for var in categorical:\n",
    "    X = make_dummy_variable(X, var)\n",
    "    X = X.loc[:,X.columns != var]\n",
    "    print 'Finished dummying variable: ' + var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_np = X.values\n",
    "y_np = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split\n",
    "\n",
    "Notum sklearn til að splitta í training og test set. Erum bara með tvær non-flokkabreytur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Séra Ng. segir að það sé betra að vera column based fyrir Neural networks svo við flippum the table.\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "X_train = np.transpose(X_train) * 1\n",
    "y_train = np.transpose(y_train)\n",
    "X_test = np.transpose(X_test) * 1\n",
    "y_test = np.transpose(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 74566\n",
      "Number of testing examples: 24856\n",
      "X_train shape: (3460, 74566)\n",
      "y_train shape: (1, 74566)\n",
      "X_test shape: (3460, 24856)\n",
      "y_test shape: (1, 24856)\n"
     ]
    }
   ],
   "source": [
    "print \"Number of training examples: \" + str(X_train.shape[1])\n",
    "print \"Number of testing examples: \" + str(X_test.shape[1])\n",
    "print \"X_train shape: \" + str(X_train.shape)\n",
    "print \"y_train shape: \" + str(y_train.shape)\n",
    "print \"X_test shape: \" + str(X_test.shape)\n",
    "print \"y_test shape: \" + str(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network með Tensorflow\n",
    "\n",
    "Þetta er mest allt copy paste'að úr námskeiðinu hans Andrew Ng nema aðlagað að okkar þörfum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    # Þetta heldur breytunum í tensorflow appinu\n",
    "    X = tf.placeholder(tf.float32, shape=(n_x, None))\n",
    "    Y = tf.placeholder(tf.float32, shape=(n_y, None))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x):\n",
    "    tf.set_random_seed(1)\n",
    "        \n",
    "    # Starta með random weights eða 0 weights í networkinu\n",
    "    W1 = tf.get_variable('W1', [50, n_x], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable('b1', [50, 1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable('W2', [25, 50], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable('b2', [25, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable('W3', [1, 25], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable('b3', [1, 1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters, keep_prob):\n",
    "    \n",
    "    # Sækja parameters\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Forward feeding                                               # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                               # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                             # A1 = relu(Z1)\n",
    "    \n",
    "    # Keep prob eyðir randomly tengingar milli neta þ.a. ábyrgðin dreyfist um allt netið.\n",
    "    # Hjálpar gegn overfitting\n",
    "    A1_dropout = tf.nn.dropout(A1, keep_prob)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1_dropout), b2)                      # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                             # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                              # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y, m, l2_loss, parameters):\n",
    "    \n",
    "    \n",
    "    pred = tf.transpose(Z3)\n",
    "    true = tf.transpose(Y)\n",
    "    \n",
    "    # Basic regression cost function með  L2 regularization\n",
    "    cost = tf.reduce_sum(tf.pow(pred-true, 2))/(2*m)\n",
    "    regularizer = tf.nn.l2_loss(parameters['W1']) + tf.nn.l2_loss(parameters['W2']) + tf.nn.l2_loss(parameters['W3'])\n",
    "    cost = tf.reduce_sum(cost + l2_loss * regularizer)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: random_mini_batches\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1,m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = int(math.floor(m/mini_batch_size)) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        \n",
    "        \n",
    "        mini_batch_X = shuffled_X[:, int(k*mini_batch_size):int((k+1)*mini_batch_size)]\n",
    "        mini_batch_Y = shuffled_Y[:, int(k*mini_batch_size):int((k+1)*mini_batch_size)]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        \n",
    "        mini_batch_X = X[:, int(mini_batch_size*(math.floor(m/mini_batch_size))):]\n",
    "        mini_batch_Y = Y[:, int(mini_batch_size*(math.floor(m/mini_batch_size))):]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, l2_loss=0.01,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True, drop = 0.2):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->Sum of Squares.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set\n",
    "    Y_train -- test set\n",
    "    X_test -- training set\n",
    "    Y_test -- test set\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 10 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters(X_train.shape[0])\n",
    "    ### END CODE HERE ###\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters, keep_prob)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    \n",
    "    ### START CODE HERE ### (1 line)\n",
    "    \n",
    "    cost = compute_cost(Z3, Y, m, l2_loss, parameters)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y, keep_prob: 1. - drop})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if epoch <= 100:\n",
    "                if print_cost == True and epoch % 10 == 0:\n",
    "                    print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if epoch > 100 and epoch <= 1000:\n",
    "                if print_cost == True and epoch % 100 == 0:\n",
    "                    print (\"Cost after epoch %i: %f\") % (epoch, epoch_cost)\n",
    "            if epoch > 1000:\n",
    "                if print_cost == True and epoch % 500 == 0:\n",
    "                    print (\"Cost after epoch %i: %f\") % (epoch, epoch_cost)\n",
    "            \n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                    costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate) + \"| L2_loss = \" + str(l2_loss))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Testing the model\n",
    "        print(\"Testing... (Mean square loss Comparison)\")\n",
    "        testing_cost = sess.run(compute_cost(Z3, Y, X_test.shape[1], l2_loss, parameters), feed_dict={X: X_test, Y: Y_test, keep_prob: 1})  # same function as cost above\n",
    "        print(\"Testing cost=\", testing_cost)\n",
    "        print(\"Absolute mean square loss difference:\", abs(\n",
    "        costs[-1] - testing_cost))\n",
    "        \n",
    "        \n",
    "        return {\"parameters\" : parameters,\n",
    "                \"testcost\" : testing_cost}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.043151\n",
      "Cost after epoch 10: 0.282474\n",
      "Cost after epoch 20: 0.260679\n",
      "Cost after epoch 30: 0.258853\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-31412094d449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m Neuralnetwork = model(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, num_epochs=200, \n\u001b[0;32m----> 2\u001b[0;31m                   l2_loss = 0.1, learning_rate = 0.0001, drop = 0.5, minibatch_size = 128)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-089b2686179a>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, Y_test, learning_rate, l2_loss, num_epochs, minibatch_size, print_cost, drop)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;31m### START CODE HERE ### (1 line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/notandi/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/notandi/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/Users/notandi/anaconda/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Neuralnetwork = model(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, num_epochs=30, \n",
    "                  l2_loss = 1, learning_rate = 0.0001, drop = 0.5, minibatch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Búið\n",
    "\n",
    "Núna ættum við að vera með fínt viðmið fyrir keyrslu á verkefninu. Getum analyzað meira til að sjá hvernig við bætum forspána mest. Ættum að greina hvort við séum að overfitta eða underfitta með því að keyra greininguna oft fyrir mismunandi úrtaksstærðir. \n",
    "\n",
    "## Hugmyndir að breytum:\n",
    "\n",
    "Er stutt í hátíð? Kóða hátíðirnar inn í þetta. Spurning hvort það væri categorical eða numeric breyta.\n",
    "\n",
    "Hreinsa olíuverðstöfluna og hafa olíuverðið með.\n",
    "\n",
    "\n",
    "### Held utan um öll costs hér fyrir neðan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testcosts = {}\n",
    "testcosts[\"10000\"] = 178.55664\n",
    "testcosts[str(size)] = Neuralnetwork[\"testcost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testcosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
